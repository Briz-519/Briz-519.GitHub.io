
<!DOCTYPE html>
<html>
  <head>
    
<meta charset="utf-8" >

<title>爬虫初体验 | Briz&#39;s home of notes</title>
<meta name="description" content="This is a site I use to store my notes">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://briz-519.github.io/favicon.ico?v=1597141565501">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://briz-519.github.io/styles/main.css">



<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>



  </head>
  <body>
    <div id="app" class="main">
      <div class="site-header-container">
  <div class="site-header">
    <div class="left">
      <a href="https://briz-519.github.io">
        <img class="avatar" src="https://briz-519.github.io/images/avatar.png?v=1597141565501" alt="" width="32px" height="32px">
      </a>
      <a href="https://briz-519.github.io">
        <h1 class="site-title">Briz&#39;s home of notes</h1>
      </a>
    </div>
    <div class="right">
      <transition name="fade">
        <i class="icon" :class="{ 'icon-close-outline': menuVisible, 'icon-menu-outline': !menuVisible }" @click="menuVisible = !menuVisible"></i>
      </transition>
    </div>
  </div>
</div>

<transition name="fade">
  <div class="menu-container" style="display: none;" v-show="menuVisible">
    <div class="menu-list">
      
        
          <a href="/" class="menu purple-link">
            首页
          </a>
        
      
        
          <a href="/archives" class="menu purple-link">
            归档
          </a>
        
      
        
          <a href="/tags" class="menu purple-link">
            标签
          </a>
        
      
        
          <a href="/post/about" class="menu purple-link">
            关于
          </a>
        
      
    </div>
  </div>
</transition>


      <div class="content-container">
        <div class="post-detail">
          
          <h2 class="post-title">爬虫初体验</h2>
          <div class="post-info post-detail-info">
            <span><i class="icon-calendar-outline"></i> 2020-08-11</span>
            
          </div>
          <div class="post-content">
            <h2 id="准备工作">准备工作</h2>
<p>首行填写防止中文乱码：#coding=utf-8</p>
<p>可加入main函数用于测试程序：</p>
<pre><code class="language-python">if __name__ ==&quot;__main__&quot;    #等同于C语言等其他语言的主函数
</code></pre>
<p>引入模块：</p>
<blockquote>
<p>本质为.py文件，用于提高代码的可维护性，可使用import来导入模块</p>
</blockquote>
<p>import sys 系统函数库</p>
<p>import bs4 网页解析获取数据</p>
<p>import sqlite3 进行SQLite数据库操作</p>
<p>import urllib.request,urllib.error 制定URL获取网页数据</p>
<p>import xlwt 进行EXCEL操作</p>
<p>import re 正则表达式进行文字匹配</p>
<blockquote>
<p><code>模块 module</code>：一般情况下，是一个以.py为后缀的文件。 module 可看作一个工具类，可共用或者隐藏代码细节，将相关代码放置在一个module以便让代码更 好用、易懂，让coder重点放在高层逻辑上。 module能定义函数、类、变量，也能包含可执行的代码。module来源有3种： ①Python内置的模块（标准库）； ②第三方模块； ③自定义模块。</p>
<p><code>包 package</code>： 为避免模块名冲突，Python引入了按目录组织模块的方法，称之为 包（package）。包 是含有Python模块的文件夹。</p>
</blockquote>
<h3 id="urllib模块">urllib模块</h3>
<p>是最基本的python内置的一个http请求库，不需要额外的安装。只需要关注请求的链接，参数，提供了强大的解析功能</p>
<p><code>urllb.request 请求模块</code></p>
<p><code>urllib.error 异常处理模块</code></p>
<p><code>urllib.parse 解析模块</code></p>
<p>简单的一个get请求</p>
<pre><code class="language-python">import urllib.request     #引入库
reponse = urllib.request.urlopen('http://www.baidu.com') 
print(reponse.read().decode('utf-8'))    #decode(&quot;utf-8&quot;)将数据解码为utf-8格式数据
</code></pre>
<p>简单的一个post请求</p>
<pre><code class="language-python">import urllib.parse
import urllib.request
data = bytes(urllib.parse.urlencode({'hello':'world'}),encoding='utf-8')
reponse = urllib.request.urlopen('http://httpbin.org/post',data=data)
print(reponse.read().decode('utf-8'))
</code></pre>
<p>超时处理</p>
<pre><code class="language-python">import urllib.request
try:
    response=urllib.request.urlopen(&quot;http://httpbin.org/get&quot;,timeout=0.01)    #设置超时时间防止无限加载
    print(response.read().decode(&quot;utf-8&quot;))
except urllib.error.URLError as e:
    print(&quot;Time out!&quot;)
</code></pre>
<pre><code class="language-python">import urllib.request
response = urllib.request.urlopen('http://www.baidu.com')
print(response.status) # 状态码 判断请求是否成功
print(response.getheaders()) # 响应头 得到的一个元组组成的列表
print(response.getheader('Server')) #得到特定的响应头
print(response.read().decode('utf-8')) #获取响应体的内容，字节流的数据，需要转成utf-8
格式
</code></pre>
<p>由于通过Pycharm获取网页信息会被网站的反爬虫识别，因此可以通过修改hearers里的user-agent来伪装成浏览器发送请求</p>
<pre><code class="language-python">from urllib import request,parse
url=&quot;http://httpbin.org/post&quot;
data=bytes(urllib.parse.urlencode({&quot;name&quot;:&quot;Briz&quot;}),encoding=&quot;utf-8&quot;)
headers={&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36 Edg/83.0.478.58&quot;}    
req=urllib.request.Request(url=url,headers=headers,data=data,method=&quot;POST&quot;)
response=urllib.request.urlopen(req)
print(response.read().decode(&quot;utf-8&quot;))

</code></pre>
<blockquote>
<p>获取user-agent方法：</p>
</blockquote>
<blockquote>
<h6 id="urlopen方法中的url参数可以是字符串也可以是一个request对象">urlopen()方法中的url参数可以是字符串，也可以是一个Request对象</h6>
</blockquote>
<pre><code class="language-python">#url可以是字符串
import urllib.request
resp = urllib.request.urlopen('http://www.baidu.com')
print(resp.read().decode('utf-8'))  # read()获取响应体的内容，内容是bytes字节流，需要转换成字符串

##url可以也是Request对象
import urllib.request
request = urllib.request.Request('http://httpbin.org')
response = urllib.request.urlopen(request)
print(response.read().decode('utf-8'))
</code></pre>
<h3 id="beautifulsoup模块">BeautifulSoup模块</h3>
<p>Beautiful Soup 是一个HTML/XML的解析器，主要的功能是如何解析和提取 HTML/XML 数据。</p>
<blockquote>
<p>BeautifulSoup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它， 则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐使用lxml 解析器。 Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方 式，除非文档没有指定一个编码方式，这时，Beautiful Soup就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了。</p>
</blockquote>
<p>创建BeautifulSoup4对象</p>
<pre><code class="language-python">from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,&quot;html.parser&quot;) # 缩进格式
</code></pre>
<h4 id="beautifulsoup4四大对象种类">BeautifulSoup4四大对象种类</h4>
<p>BeautifulSoup4将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以 归纳为4种:</p>
<p><code>Tag</code></p>
<p><code>NavigableString</code></p>
<p><code>BeautifulSoup</code></p>
<p><code>Comment</code></p>
<h5 id="tag">Tag</h5>
<p>Tag通俗点讲就是HTML中的一个个标签，例如：</p>
<pre><code class="language-python">from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,&quot;html.parser&quot;)

print(bs.title)# 获取title标签的所有内容

print(bs.head)# 获取head标签的所有内容

print(bs.a)# 获取第一个a标签的所有内容

print(type(bs.a))# 类型
</code></pre>
<blockquote>
<p>我们可以利用 soup 加标签名轻松地获取这些标签的内容，这些对象的类型是bs4.element.Tag。但是，它查找的是在所有内容中的<code>第一个</code>符合要求的标签(不包括被注释的)。</p>
</blockquote>
<p>对于 Tag，它有两个重要的属性，是 name 和 attrs：</p>
<pre><code class="language-python">from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,&quot;html.parser&quot;)

print(bs.name)# [document] #bs 对象本身比较特殊，它的 name 即为 [document]

print(bs.head.name)# head #对于其他内部标签，输出的值便为标签本身的名称

print(bs.a.attrs)# 把 a 标签的所有属性打印输出了出来，得到的类型是一个字典。

print(bs.a['class']) # 等价 bs.a.get('class')

bs.a['class'] = &quot;newClass&quot;# 可以对这些属性和内容等等进行修改

del bs.a['class']# 对这个属性进行删除

</code></pre>
<h5 id="navigablestring">NavigableString</h5>
<pre><code class="language-python">from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,&quot;html.parser&quot;)
print(bs.title.string)    #获取标签内部的文字
print(type(bs.title.string))
</code></pre>
<h5 id="beautifulsoup">BeautifulSoup</h5>
<p>BeautifulSoup对象表示的是一个文档的内容。大部分时候，可以把它当作 Tag 对象，是一个特殊的 Tag，我们可以分别获取它的类型，名称，以及属性</p>
<pre><code class="language-python">from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,&quot;html.parser&quot;)
print(type(bs.name))
print(bs.name)
print(bs.attrs)
{'class': ['mnav'], 'href': 'http://news.baidu.com', 'name': 'tj_trnews'}
</code></pre>
<h5 id="comment">Comment</h5>
<p>Comment 对象是一个特殊类型的 NavigableString 对象，其输出的内容不包括注释符号</p>
<pre><code class="language-python">from bs4 import BeautifulSoup
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,&quot;html.parser&quot;)
print(bs.a)
# 此时不能出现空格和换行符，a标签如下：
# &lt;a class=&quot;mnav&quot; href=&quot;http://news.baidu.com&quot; name=&quot;tj_trnews&quot;&gt;&lt;!--新闻--&gt;&lt;/a&gt;
print(bs.a.string) # 新闻
print(type(bs.a.string)) # &lt;class 'bs4.element.Comment'&gt;
</code></pre>
<h4 id="遍历文档树">遍历文档树</h4>
<p>5.1 .contents：获取Tag的所有子节点，返回一个list</p>
<pre><code class="language-python"># tag的.content 属性可以将tag的子节点以列表的方式输出
print(bs.head.contents)
# 用列表索引来获取它的某一个元素
print(bs.head.contents[1])
</code></pre>
<p>5.2 .children：获取Tag的所有子节点，返回一个生成器</p>
<pre><code class="language-python">for child in bs.body.children:
print(child)
</code></pre>
<blockquote>
<p>5.3、.descendants：获取Tag的所有子孙节点</p>
<p>5.4、.strings：如果Tag包含多个字符串，即在子孙节点中有内容，可以用此获取，而后进行遍历</p>
<p>5.5、.stripped_strings：与strings用法一致，只不过可以去除掉那些多余的空白内容</p>
<p>5.6、.parent：获取Tag的父节点</p>
<p>5.7、.parents：递归得到父辈元素的所有节点，返回一个生成器</p>
<p>5.8、.previous_sibling：获取当前Tag的上一个节点，属性通常是字符串或空白，真实结果是当前标签 与上一个标签之间的顿号和换行符</p>
<p>5.9、.next_sibling：获取当前Tag的下一个节点，属性通常是字符串或空白，真是结果是当前标签与下 一个标签之间的顿号与换行符</p>
<p>5.10、.previous_siblings：获取当前Tag的上面所有的兄弟节点，返回一个生成器</p>
<p>5.11、.next_siblings：获取当前Tag的下面所有的兄弟节点，返回一个生成器</p>
<p>5.12、.previous_element：获取解析过程中上一个被解析的对象(字符串或tag)，可能与 previous_sibling相同，但通常是不一样的</p>
<p>5.13、.next_element：获取解析过程中下一个被解析的对象(字符串或tag)，可能与next_sibling相同， 但通常是不一样的</p>
<p>5.14、.previous_elements：返回一个生成器，可以向前访问文档的解析内容</p>
<p>5.15、.next_elements：返回一个生成器，可以向后访问文档的解析内容</p>
<p>5.16、.has_attr：判断Tag是否包含属性</p>
</blockquote>
<h4 id="搜索文档树">搜索文档树</h4>
<p>find_all(name, attrs, recursive, text, **kwargs)</p>
<h5 id="name参数">name参数：</h5>
<p>字符串过滤：会查找与字符串完全匹配的内容</p>
<pre><code class="language-python">a_list = bs.find_all(&quot;a&quot;)
print(a_list)
</code></pre>
<p>正则表达式过滤：如果传入的是正则表达式，那么BeautifulSoup4会通过search()来匹配内容</p>
<pre><code class="language-python">from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,&quot;html.parser&quot;)
t_list = bs.find_all(re.compile(&quot;a&quot;))    #列表输出所有带a的标签
for item in t_list:
print(item)
</code></pre>
<h5 id="kwargs参数">kwargs参数：</h5>
<pre><code class="language-python">from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html,&quot;html.parser&quot;)
# 查询id=head的Tag
t_list = bs.find_all(id=&quot;head&quot;)
print(t_list)
# 查询href属性包含news.baidu.com的Tag
t_list = bs.find_all(href=re.compile(&quot;http://news.baidu.com&quot;))
print(t_list)
# 查询所有包含class的Tag(注意：class在Python中属于关键字，所以加_以示区别)
t_list = bs.find_all(class_=True)
for item in t_list:
print(item)
</code></pre>
<h5 id="text参数">text参数：</h5>
<p>通过text参数可以搜索文档中的字符串内容，与name参数的可选值一样，text参数接受 字符串，正则 表达式，列表</p>
<pre><code class="language-python">from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html, &quot;html.parser&quot;)
t_list = bs.find_all(attrs={&quot;data-foo&quot;: &quot;value&quot;})
for item in t_list:
print(item)
t_list = bs.find_all(text=&quot;hao123&quot;)
for item in t_list:
print(item)
t_list = bs.find_all(text=[&quot;hao123&quot;, &quot;地图&quot;, &quot;贴吧&quot;])
for item in t_list:
print(item)
t_list = bs.find_all(text=re.compile(&quot;\d&quot;))    #带有数字的内容
for item in t_list:
print(item)
</code></pre>
<p>当我们搜索text中的一些特殊属性时，同样也可以传入一个方法来达到我们的目的：</p>
<pre><code class="language-python">def length_is_two(text):
return text and len(text) == 2
t_list = bs.find_all(text=length_is_two)
for item in t_list:
print(item)
</code></pre>
<h5 id="limit参数">limit参数：</h5>
<p>可以传入一个limit参数来限制返回的数量，当搜索出的数据量为5，而设置了limit=2时，此时只会返回 前2个数据</p>
<pre><code class="language-python">from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html, &quot;html.parser&quot;)
t_list = bs.find_all(&quot;a&quot;,limit=2)
for item in t_list:
print(item)
</code></pre>
<p>find_all除了上面一些常规的写法，还可以对其进行一些简写：</p>
<pre><code class="language-python"># 两者是相等的
# t_list = bs.find_all(&quot;a&quot;) =&gt; t_list = bs(&quot;a&quot;)
t_list = bs(&quot;a&quot;) # 两者是相等的
# t_list = bs.a.find_all(text=&quot;新闻&quot;) =&gt; t_list = bs.a(text=&quot;新闻&quot;)
t_list = bs.a(text=&quot;新闻&quot;)
</code></pre>
<p>find()</p>
<p>find()将返回符合条件的第一个Tag，有时我们只需要或一个Tag时，我们就可以用到find()方法了。当然 了，也可以使用find_all()方法，传入一个limit=1，然后再取出第一个值也是可以的，不过未免繁琐。</p>
<pre><code class="language-python">from bs4 import BeautifulSoup
import re
file = open('./aa.html', 'rb')
html = file.read()
bs = BeautifulSoup(html, &quot;html.parser&quot;)
# 返回只有一个结果的列表
t_list = bs.find_all(&quot;title&quot;,limit=1)
print(t_list)
# 返回唯一值
t = bs.find(&quot;title&quot;)
print(t)
# 如果没有找到，则返回None
t = bs.find(&quot;abc&quot;) print(t)
#从结果可以看出find_all，尽管传入了limit=1，但是返回值仍然为一个列表，当我们只需要取一个值时，远不如find方法方便。但是如果未搜索到值时，将返回一个None
</code></pre>
<h4 id="css选择器">CSS选择器</h4>
<p>BeautifulSoup支持发部分的CSS选择器，在Tag获取BeautifulSoup对象的.select()方法中传入字符串参 数，即可使用CSS选择器的语法找到Tag:</p>
<p>7.1、通过标签名查找</p>
<pre><code class="language-python">print(bs.select('title'))
print(bs.select('a'))
</code></pre>
<p>7.2、通过类名查找</p>
<p>print(bs.select('.mnav'))    #.对应class</p>
<p>7.3、通过id查找</p>
<p>print(bs.select('#u1'))    ##对应id</p>
<p>7.4、组合查找</p>
<p>print(bs.select('div .bri'))    #div标签内id为bri</p>
<p>7.5、属性查找</p>
<p>print(bs.select('a[class=&quot;bri&quot;]'))</p>
<p>print(bs.select('a[href=&quot;http://tieba.baidu.com&quot;]'))</p>
<p>7.6、直接子标签查找</p>
<p>t_list = bs.select(&quot;head &gt; title&quot;)</p>
<p>print(t_list)</p>
<p>7.7、兄弟节点标签查找</p>
<p>t_list = bs.select(&quot;.mnav ~ .bri&quot;)</p>
<p>print(t_list)</p>
<p>7.8、获取内容</p>
<p>t_list = bs.select(&quot;title&quot;)</p>
<p>print(bs.select('title')[0].get_text())    #获取title标签内的内容</p>
<h3 id="re模块">re模块</h3>
<h4 id="正则表达式常用操作符">正则表达式常用操作符</h4>
<table>
<thead>
<tr>
<th>操作符</th>
<th>说明</th>
<th>实例</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>表示任何单个字符</td>
<td></td>
</tr>
<tr>
<td>[ ]</td>
<td>字符集，对单个字符给予取值范围</td>
<td>[abc]表示a,b,c，[a-z]表示a到z单个字符</td>
</tr>
<tr>
<td>[^ ]</td>
<td>非字符集，对单个字符给出取值范围</td>
<td>[^abc]表示非a或b或c的单个字符</td>
</tr>
<tr>
<td>*</td>
<td>前一个字符<code>0</code>次或无限次扩展</td>
<td>abc*表示ab,abc,abcc,abccc等</td>
</tr>
<tr>
<td>+</td>
<td>前一个字符<code>1</code>次或无限次扩展</td>
<td>abc+表示abc,abcc,abccc等</td>
</tr>
<tr>
<td>？</td>
<td>前一个字符0次或1次扩展</td>
<td>abc?表示ab,abc</td>
</tr>
<tr>
<td>|</td>
<td>左右表达式任意一个</td>
<td>abc|def表示abc,def</td>
</tr>
<tr>
<td>{m}</td>
<td>扩展前一个字符m次</td>
<td>ab{2}c表示abbc</td>
</tr>
<tr>
<td>{m,n}</td>
<td>扩展前一个字符m至n次（含n）</td>
<td>ab{1,3}c表示abc,abbc,abbbc</td>
</tr>
<tr>
<td>^</td>
<td>匹配字符串开头</td>
<td>^abc表示abc且在一个字符串的开头</td>
</tr>
<tr>
<td>$</td>
<td>匹配字符串结尾</td>
<td>abc$表示abc且在一个字符串的结尾</td>
</tr>
<tr>
<td>( )</td>
<td>分组标记，内部可使用|操作符</td>
<td>(abc)表示abc ,(abc|def)表示abc，def</td>
</tr>
<tr>
<td>\d</td>
<td>数字，等价于[0-9]</td>
<td></td>
</tr>
<tr>
<td>\w</td>
<td>单词字符，等价于[A-Z]/[a-z]/[0-9]/_</td>
<td>网站注册用户名(只能使用大小写字母数字和下划线 )</td>
</tr>
</tbody>
</table>
<blockquote>
<p>“?” ：0次或1次，match,search 不会出现none，会出现’ ‘ （因为0次也是符合的） 0次或1次不是指[xxx]这个集合，而是其中的任何的一个字符</p>
<pre><code class="language-python">pat = re.compile( [abc]? )
pat.match( defabc ).group() #0次
pat.match( abcdefabc ).group()
&gt;&gt;&gt; a
pat.search( defabc ).group() #0次
pat.findall( defabc ) #0次和1次
&gt;&gt;&gt; [ , , , a , b , c , ]
</code></pre>
<p>“数量词?” ：<code>非贪婪模式</code>：只匹配最少的（尽可能少）；默认贪婪模式：匹配最多的（尽可能多）</p>
<pre><code class="language-python">pat = re.compile( [abc]+ ) #贪婪模式
&gt;&gt;&gt; pat.match( abcdefabcabc ).group() #匹配尽可能多的：abc
&gt;&gt;&gt; abc
&gt;&gt;&gt; pat.match( bbabcdefabcabc ).group()
&gt;&gt;&gt; bbabc
&gt;&gt;&gt; pat.search( dbbabcdefabcabc ).group()
&gt;&gt;&gt; bbabc
&gt;&gt;&gt; pat.findall( abcdefabcabc )
&gt;&gt;&gt; [ abc , abcabc ]
&gt;&gt;&gt; pat = re.compile( [abc]+? ) #非贪婪模式：+?
&gt;&gt;&gt; pat.match( abcdefabcabc ).group() #匹配尽可能少的：a、b、c
&gt;&gt;&gt; a
&gt;&gt;&gt; pat.search( dbbabcdefabcabc ).group()
&gt;&gt;&gt; b
&gt;&gt;&gt; pat.findall( abcdefabcabc )
&gt;&gt;&gt; [ a , b , c , a , b , c , a , b , c ]
</code></pre>
</blockquote>
<h4 id="re库主要功能函数">Re库主要功能函数</h4>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.search()</td>
<td>在一个字符串中国搜索匹配正则表达式的第一个位置，<code>返回match对象</code></td>
</tr>
<tr>
<td>re.match()</td>
<td>从一个字符串的开始位置起匹配正则表达式，<code>返回match对象</code></td>
</tr>
<tr>
<td>re.findall()</td>
<td>搜索字符串，以列表类型返回全部能匹配的子串</td>
</tr>
<tr>
<td>re.split()</td>
<td>将一个字符串按照正则表达式匹配结果进行分隔，返回列表类型</td>
</tr>
<tr>
<td>re.finditer()</td>
<td>搜索字符串，返回一个匹配结果的迭代类型，<code>每个迭代对象是match对象</code></td>
</tr>
<tr>
<td>re.sub()</td>
<td>在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</td>
</tr>
</tbody>
</table>
<blockquote>
<p>正则表达式可以包含一些可选标志修饰符来控制匹配的模式。修饰符被指定为一个可选的标志。 多个标志可以通过按位 OR(|) 它们来指定。如 re.I | re.M 被设置成 I 和 M 标志：</p>
<table>
<thead>
<tr>
<th>修饰符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.I</td>
<td>使匹配对大小写不敏感</td>
</tr>
<tr>
<td>re.L</td>
<td>做本地化识别（locale-aware）匹配</td>
</tr>
<tr>
<td>re.M</td>
<td>多行匹配，影响 ^ 和 $</td>
</tr>
<tr>
<td>re.S</td>
<td>使 . 匹配包括换行在内的所有字符</td>
</tr>
<tr>
<td>re.U</td>
<td>根据Unicode字符集解析字符。这个标志影响 \w, \W, \b, \B.</td>
</tr>
<tr>
<td>re.X</td>
<td>该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解。</td>
</tr>
</tbody>
</table>
</blockquote>
<h5 id="函数具体用法">函数具体用法</h5>
<h6 id="compilepattern创建模式对象">compile(pattern)：创建模式对象</h6>
<pre><code class="language-python">import re
pat=re.compile(&quot;A&quot;)
#m=pat.search(&quot;CBA&quot;)
m=pat.search(&quot;ABC&quot;)
#等价于 re.search( A , CBA )
print(m)
#&lt;re.Match object; span=(2, 3), match='A'&gt; 表示匹配到了
m=pat.search(&quot;CBD&quot;)
print(m) #None 表示没匹配到
</code></pre>
<h6 id="searchpatternstring在字符串中寻找模式">search(pattern,string)：在字符串中寻找模式</h6>
<pre><code class="language-python">import re
m = re.search(&quot;asd&quot; , &quot;ASDasd&quot; )
print(m)
# &lt;_sre.SRE_Match object at 0xb72cd6e8&gt; #匹配到了，返回MatchObject（True）
m = re.search(&quot;asd&quot; , &quot;ASDASD&quot; )
print(m)     #表示没匹配到返回None(False)
</code></pre>
<h6 id="matchpatternstring在字符串开始处匹配模式">match(pattern,string)：在字符串开始处匹配模式</h6>
<pre><code class="language-python"># 等价于
pat=re.compile( &quot;a&quot; )
print(pat.match( &quot;Aasd&quot; ))
#输出None
print(pat.match(&quot;aASD&quot; ))
#输出 &lt;_sre.SRE_Match object at 0xb72cd6e8&gt;
# 上面的函数返回都可以在if条件语句中进行判断：
if pat.search(&quot;asd&quot;):
print (&quot;OK&quot;) #OK #找到返回
if re.search(&quot;a&quot;,&quot;ASD&quot; ):
print (&quot;OK&quot;) #没有找到
</code></pre>
<h6 id="splitpatternstring根据模式分割字符串返回列表">split(pattern,string)：根据模式分割字符串,返回列表</h6>
<pre><code class="language-python">re.split( , , a,s,d,asd )
[ a , s , d , asd ] #返回列表
pat = re.compile( , )
pat.split( a,s,d,asd )
[ a , s , d , asd ] #返回列表
re.split( [, ]+ , a , s ,d ,,,,,asd ) #正则匹配：[, ]+
[ a , s , d , asd ]
re.split( [, ]+ , a , s ,d ,,,,,asd ,maxsplit=2) # maxsplit 最多分割次数
[ a , s , d ,,,,,asd ]
pat = re.compile( [, ]+ ) #正则匹配：[, ]+
pat.split( a , s ,d ,,,,,asd ,maxsplit=2) # maxsplit 最多分割次数
[ a , s , d ,,,,,asd ]
</code></pre>
<h6 id="findallpatternstring列表形式返回匹配项">findall(pattern,string)：列表形式返回匹配项</h6>
<pre><code class="language-python">import re
print(re.findall( &quot;a&quot; , &quot;ASDaDFGAa&quot; ))
#[ a , a ] #列表形式返回匹配到的字符串
pat = re.compile( &quot;a&quot; )
print(pat.findall( &quot;ASDaDFGAa&quot; ))
#[ a , a ] #列表形式返回匹配到的字符串
pat = re.compile( &quot;[A-Z]+&quot; ) #正则匹配：[A-Z]+ 前一个字符`1`次或无限次扩展
print(pat.findall( &quot;ASDcDFGAa&quot; ))
#[ ASD , DFGA ] #找到匹配到的字符串
pat = re.compile( [A-Z] )
pat.findall( ASDcDFGAa )
[ A , S , D , D , F , G , A ] #找到匹配到的字符串
pat = re.compile( [A-Za-z] ) #正则匹配：[A-Za-z]+ 匹配所有字母
pat.findall( ASDcDFGAa )
[ A , S , D , c , D , F , G , A , a ]
</code></pre>
<h6 id="subpatreplstring-用repl替换-pat匹配项-留的是中间的因为中间在中心">sub(pat,repl,string) ：用repl替换 pat匹配项 (留的是中间的，因为中间在中心)</h6>
<pre><code class="language-python">re.sub( a , A , abcasd ) #找到a用A替换，后面见和group的配合使用
AbcAsd
pat = re.compile( a )
pat.sub( A , abcasd )
AbcAsd
pat=re.compile(r www.(.*)..{3} ) #正则表达式
#在Python的string前面加上‘r’， 是为了告诉编译器这个string是个raw string，不要转译反斜杠
#例如， 在raw string中，是两个字符，和n， 而不会转译为换行符。
#由于正则表达式和 会有冲突，因此，当一个字符串使用了正则表达式后，最好在前面加上 r 。
#与大多数编程语言相同，正则表达式里使用&quot;&quot;作为转义字符，这就可能造成反斜杠困扰。
#假如你需要匹配文本中的字符&quot;&quot;，那么使用编程语言表示的正则表达式里将需要4个反斜杠&quot;\\&quot;：
#前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。
#Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r&quot;\&quot;表示。
#同样，匹配一个数字的&quot;\d&quot;可以写成r&quot;d&quot;。
#有了原生字符串，你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。
#不是说 加了r 就没有转译功能，好乱，就直接记住1句话：
#当一个字符串使用了正则表达式后，最好在前面加上 r ，这样你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观
pat.match( www.dxy.com ).group(1)
dxy
re.sub(r www.(.*)..{3} ,r , hello,www.dxy.com )
pat.sub(r , hello,www.dxy.com )
hello,dxy
# r 1 是第一组的意思
#通过正则匹配找到符合规则的&quot;www.dxy.com&quot; ，取得 组1字符串 去替换 整个匹配。
pat=re.compile(r (w+) (w+) ) #正则表达式
s= hello world ! hello hz !
pat.findall( hello world ! hello hz ! )
[( hello , world ), ( hello , hz )]
pat.sub(r ,s) #通过正则得到组1(hello)，组2(world)，再通过sub去替换。
即组1替换组2，组2替换组1，调换位置。
world hello!hz hello!
</code></pre>
<h3 id="xlwt模块">xlwt模块</h3>
<pre><code class="language-python">import xlwt #导入模块
workbook = xlwt.Workbook(encoding='utf-8') #创建workbook 对象
worksheet = workbook.add_sheet('sheet1') #创建工作表sheet
worksheet.write(0, 0, 'hello') #往表中写内容,第一各参数 行,第二个参数列,第三个参数内容
workbook.save('students.xls') #保存表为students.xls
</code></pre>
<p>将九九乘法表显示在表格中，每个单元格1个公式</p>
<pre><code class="language-python">workbook = xlwt.Workbook(encoding='utf-8') #创建workbook 对象
worksheet = workbook.add_sheet('sheet1') #创建工作表sheet
for i in range(0,9):
for j in range(0,i+1):
worksheet.write(i, j, &quot;%d * %d = %d&quot;%(i+1,j+1,(i+1)*(j+1)))
# worksheet.write(0, 0, 'hello') #往表中写内容,第一各参数 行,第二个参数列,第三个参数内容
workbook.save('students.xls') #保存表为students.xls
</code></pre>

          </div>
        </div>

        
          <div class="next-post">
            <a class="purple-link" href="https://briz-519.github.io/post/hello-gridea/">
              <h3 class="post-title">
                下一篇：Hello Gridea
              </h3>
            </a>
          </div>
          
      </div>

      

      <div class="site-footer">
  <div class="slogan">This is a site I use to store my notes</div>
  <div class="social-container">
    
      
        <a href="https://github.com/Briz-519" target="_blank">
          <i class="fab fa-github"></i>
        </a>
      
    
      
    
      
        <a href="https://weibo.com/5672564737/profile?topnav=1&amp;wvr=6" target="_blank">
          <i class="fab fa-weibo"></i>
        </a>
      
    
      
    
      
    
  </div>
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://briz-519.github.io/atom.xml" target="_blank">RSS</a>
</div>


    </div>
    <script type="application/javascript">

hljs.initHighlightingOnLoad()

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>




  </body>
</html>
